{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "1. Neural Networks\n",
    "\n",
    "    1.1 Multilayer neural networks\n",
    "\n",
    "2. Deep Learning in `keras`\n",
    "\n",
    "    2.1 Keras optimizer\n",
    "    \n",
    "3. CNN (Convolutional neural network)\n",
    "\n",
    "4. Pooling\n",
    "\n",
    "5. Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t08IWzpL-6jF"
   },
   "source": [
    "## 1. Neural Networks\n",
    "\n",
    "Neural nets are a specific method for learning from data, a method that is based on a very simple element, the *neuron unit*. A neuron unit (or 1-layer neural network) is a mathematical function of this kind:\n",
    "\n",
    "${\\mathbf y} = \\sigma(\\mathbf{w}^T \\cdot {\\mathbf x} + b)$\n",
    "\n",
    "where ${\\mathbf x}$ represents an input element in vector form, $\\mathbf{w}$ is a vector of weights,  $\\sigma$ is a non-linear function and $b$ a scalar value. $(\\mathbf{w},b)$ are called the parameters of the function. The output of this function is called the *activation* of the neuron. \n",
    "\n",
    "Regarding the non-linear function, historically the most common one was the Sigmoid function, but nowadays there are several alternatives that are supposed to be better suited to learning from data, such as ReLU and variants.\n",
    "\n",
    "> **Question:** What kind of decision functions are represented by a 1-layer nn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 925,
     "status": "ok",
     "timestamp": 1647940942543,
     "user": {
      "displayName": "Jordi Vitrià",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmEyLlUae4iKg7mL0rlGD0T7qj1Bpbxe-TmXfZBog=s64",
      "userId": "02382397723117011615"
     },
     "user_tz": -60
    },
    "id": "FX5NwyDo_A_P",
    "outputId": "6db56d70-c551-4f68-d122-60a53957b6e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10e0bb100>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def ReLU(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "plt.ylim(-1.5, 10)\n",
    "x = np.linspace(-10.0,10.0,100)\n",
    "y1 = sigmoid(x)\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(x,y1)\n",
    "y2 = ReLU(x)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(x,y2,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1647940943094,
     "user": {
      "displayName": "Jordi Vitrià",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmEyLlUae4iKg7mL0rlGD0T7qj1Bpbxe-TmXfZBog=s64",
      "userId": "02382397723117011615"
     },
     "user_tz": -60
    },
    "id": "RX5LERmbBQaR",
    "outputId": "2a00806e-162f-40fb-a1f0-64aa01e2937b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994997988929205\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.4,1.2,3.5])\n",
    "\n",
    "w = np.array([1.0,2.0,1.0])\n",
    "b = 1.3\n",
    "\n",
    "y = sigmoid(np.dot(x,w) + b)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2P7yHSro_Inc"
   },
   "source": [
    "## 1.1 Multilayer neural networks\n",
    "\n",
    "Simple neurons can be organized in larger structures by applying to the same data vector different sets of weights, forming what is called a *layer*, and by stacking layers one on top of the output of the other.  \n",
    "\n",
    "It is important to notice that a multilayer neural network can be seen as a composition of matrix products (matrices represent weights) and non-linear function activations. For the case of a 2-layer network the outcome is:\n",
    "\n",
    "$ {\\mathbf y} = {\\mathbf \\sigma}\\Big( W^1  {\\mathbf \\sigma}\\Big( W^0  {\\mathbf x} + {\\mathbf b}^0 \\Big) + {\\mathbf b}^1 \\Big)$\n",
    "\n",
    "where ${\\mathbf \\sigma}$ represents a vectorial version of the sigmoid function and $W^i$ are the weights of each layer in matrix form.  \n",
    "\n",
    "What is interesting about this kind of structures is that it has been showed that even a neural network with a single hidden layer containing a finite number of neurons can approximate any continuous function of $\\mathbf{R}^n$. This fact makes neural networks a sound candidate to implement learning from data methods. The question is then: how to find the optimal parameters, ${\\mathbf w} = (W^i,{\\mathbf b})$, to approximate a function that is implicitly defined by a set of samples $\\{({\\mathbf x}_1, {\\mathbf y}_1), \\dots,  ({\\mathbf x}_n, {\\mathbf y}_n)\\}$?\n",
    "\n",
    "From a technical point of view, not only neural networks but most of the algorithms that have been proposed to infer models from large data sets are based on the iterative solution of a mathematical problem that involves data and a mathematical model. If there was an analytic solution to the problem, this should be the adopted one, but this is not the case for most of the cases. The techniques that have been designed to tackle these problems are grouped under a field that is called optimization. The most important technique for solving optimization problems is *gradient descend*.\n",
    "\n",
    "> The training of models like $ {\\mathbf y} = {\\mathbf \\sigma}\\Big( W^1  {\\mathbf \\sigma}\\Big( W^0  {\\mathbf x} + {\\mathbf b}^0 \\Big) + {\\mathbf b}^1 \\Big)$ (or bigger!) can be readily performed by applying *automatic differentiation* to a loss function. \n",
    "\n",
    "> In the case of regression: $L = \\frac{1}{n} \\sum_{i=1}^n \\Big({\\mathbf y}_i - {\\mathbf \\sigma}\\Big( W^1  {\\mathbf \\sigma}\\Big( W^0  {\\mathbf x}_i + {\\mathbf b}^0 \\Big) + {\\mathbf b}^1 )\\Big)\\Big)^2 $\n",
    "\n",
    "> In the case of two-class classification: $L = \\frac{1}{n} log(1 + exp(-y_i {\\mathbf \\sigma}\\Big( W^1  {\\mathbf \\sigma}\\Big( W^0  {\\mathbf x} + {\\mathbf b}^0 \\Big) + {\\mathbf b}^1 \\Big))) $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eMoVJNwZB81F"
   },
   "source": [
    "## Playing with neural nets.\n",
    "+ Concentric classes, 1 layer, Sigmoid.\n",
    "+ Concentric classes, 1 layer, ReLu.\n",
    "+ X-or, 0 layer.\n",
    "+ X-or, 1 layer.\n",
    "+ Spiral data.\n",
    "+ Regression.\n",
    "\n",
    "\n",
    "http://playground.tensorflow.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqXdykt2DYo0"
   },
   "source": [
    "## 2. Deep Learning in `keras`\n",
    "\n",
    "> Keras is a high-level neural networks library, written in Python and capable of running on top TensorFlow. It was developed with a focus on enabling fast experimentation.\n",
    "\n",
    "The core data structure of Keras is a model, a way to organize layers. The main type of model is the ``Sequential model``, a linear stack of layers. \n",
    "\n",
    "```Python\n",
    "from tensorflow.keras.models import Sequential\n",
    "model = Sequential()\n",
    "```\n",
    "\n",
    "Stacking layers is as easy as ``.add()``:\n",
    "\n",
    "```Python\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "\n",
    "model.add(Dense(output_dim=64, input_dim=100))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(output_dim=10))\n",
    "model.add(Activation(\"softmax\"))\n",
    "```\n",
    "\n",
    "Once your model looks good, configure its learning process with ``.compile()``:\n",
    "\n",
    "```Python\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='sgd', metrics=['accuracy'])\n",
    "```\n",
    "\n",
    "If you need to, you can further configure your optimizer.\n",
    "\n",
    "```Python\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True))\n",
    "```\n",
    "\n",
    "You can now iterate on your training data in batches:\n",
    "\n",
    "```Python\n",
    "model.fit(X_train, Y_train, nb_epoch=5, batch_size=32)\n",
    "```\n",
    "\n",
    "Evaluate your performance in one line:\n",
    "```Python\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "```\n",
    "\n",
    "Or generate predictions on new data:\n",
    "\n",
    "```Python\n",
    "classes = model.predict_classes(X_test, batch_size=32)\n",
    "proba = model.predict_proba(X_test, batch_size=32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 4570,
     "status": "ok",
     "timestamp": 1647973580497,
     "user": {
      "displayName": "Jordi Vitrià",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmEyLlUae4iKg7mL0rlGD0T7qj1Bpbxe-TmXfZBog=s64",
      "userId": "02382397723117011615"
     },
     "user_tz": -60
    },
    "id": "uqHskK3EZQx_",
    "outputId": "090838ac-541c-419a-b597-dd3bcc3f8da6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1647973580498,
     "user": {
      "displayName": "Jordi Vitrià",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmEyLlUae4iKg7mL0rlGD0T7qj1Bpbxe-TmXfZBog=s64",
      "userId": "02382397723117011615"
     },
     "user_tz": -60
    },
    "id": "3htJMJEualOT",
    "outputId": "7327f3f4-8978-411d-9c90-c2631ba216bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 9966867280947028890\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84137,
     "status": "ok",
     "timestamp": 1647974669140,
     "user": {
      "displayName": "Jordi Vitrià",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmEyLlUae4iKg7mL0rlGD0T7qj1Bpbxe-TmXfZBog=s64",
      "userId": "02382397723117011615"
     },
     "user_tz": -60
    },
    "id": "xEufgoGHDytG",
    "outputId": "88b3db0a-0c46-4686-d506-67ef9d3232a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,560</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │        \u001b[38;5;34m12,560\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,434</span> (52.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,434\u001b[0m (52.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,434</span> (52.48 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,434\u001b[0m (52.48 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5979 - loss: 1.2028 - val_accuracy: 0.9078 - val_loss: 0.3224\n",
      "Epoch 2/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - accuracy: 0.8305 - loss: 0.5441 - val_accuracy: 0.9246 - val_loss: 0.2607\n",
      "Epoch 3/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 871us/step - accuracy: 0.8555 - loss: 0.4686 - val_accuracy: 0.9300 - val_loss: 0.2391\n",
      "Epoch 4/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8678 - loss: 0.4282 - val_accuracy: 0.9360 - val_loss: 0.2227\n",
      "Epoch 5/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.8733 - loss: 0.4182 - val_accuracy: 0.9369 - val_loss: 0.2175\n",
      "Epoch 6/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.8802 - loss: 0.3951 - val_accuracy: 0.9394 - val_loss: 0.2149\n",
      "Epoch 7/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - accuracy: 0.8808 - loss: 0.3960 - val_accuracy: 0.9393 - val_loss: 0.2064\n",
      "Epoch 8/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.8883 - loss: 0.3805 - val_accuracy: 0.9406 - val_loss: 0.2030\n",
      "Epoch 9/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.8846 - loss: 0.3850 - val_accuracy: 0.9420 - val_loss: 0.2019\n",
      "Epoch 10/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 881us/step - accuracy: 0.8875 - loss: 0.3778 - val_accuracy: 0.9389 - val_loss: 0.2101\n",
      "Epoch 11/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 0.8904 - loss: 0.3665 - val_accuracy: 0.9450 - val_loss: 0.2012\n",
      "Epoch 12/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8926 - loss: 0.3617 - val_accuracy: 0.9429 - val_loss: 0.1984\n",
      "Epoch 13/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 0.8949 - loss: 0.3626 - val_accuracy: 0.9440 - val_loss: 0.2015\n",
      "Epoch 14/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 0.8907 - loss: 0.3634 - val_accuracy: 0.9441 - val_loss: 0.2026\n",
      "Epoch 15/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 863us/step - accuracy: 0.8917 - loss: 0.3615 - val_accuracy: 0.9422 - val_loss: 0.1993\n",
      "Epoch 16/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.8970 - loss: 0.3553 - val_accuracy: 0.9435 - val_loss: 0.2010\n",
      "Epoch 17/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.8960 - loss: 0.3577 - val_accuracy: 0.9436 - val_loss: 0.2024\n",
      "Epoch 18/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 772us/step - accuracy: 0.8955 - loss: 0.3592 - val_accuracy: 0.9400 - val_loss: 0.2111\n",
      "Epoch 19/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 807us/step - accuracy: 0.8952 - loss: 0.3538 - val_accuracy: 0.9464 - val_loss: 0.2049\n",
      "Epoch 20/20\n",
      "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - accuracy: 0.8954 - loss: 0.3542 - val_accuracy: 0.9432 - val_loss: 0.2076\n",
      "Test loss: 0.20761482417583466\n",
      "Test accuracy: 0.9431999921798706\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljANZSaIYe8I"
   },
   "source": [
    "#### Dropout\n",
    "\n",
    "Dropout is a way to regularize the neural network. During training, it may happen that neurons of a particular layer may always become influenced only by the output of a particular neuron in the previous layer. In that case, the neural network would overfit.\n",
    "\n",
    "Dropout prevents overfitting and regularizes by randomly cutting the connections (also known as dropping the connection) between neurons in successecutive layers during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i22znQv4bA1Q"
   },
   "source": [
    "### 2.1 Keras optimizers\n",
    "\n",
    "There are several variants of gradient descent, which differ in how we compute the step.\n",
    "\n",
    "Keras supports seven optimizers.\n",
    "\n",
    "```python\n",
    "my_opt = tensorflow.keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "my_opt = tensorflow.keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "my_opt = tensorflow.keras.optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "my_opt = tensorflow.keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "my_opt = tensorflow.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "my_opt = tensorflow.keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "my_opt = tensorflow.keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "```\n",
    "\n",
    "#### Momentum\n",
    "\n",
    "For example, SGD has trouble navigating ravines, i.e. areas where the surface curves much more steeply in one dimension than in another, which are common around local optima. In these scenarios, SGD oscillates across the slopes of the ravine while only making hesitant progress along the bottom towards the local optimum.\n",
    "\n",
    "Momentum is a method that helps accelerate SGD in the relevant direction and dampens oscillations. It does this by adding a fraction of the update vector of the past time step to the current update vector:\n",
    "\n",
    "$$ v_t = m v_{t-1} + \\alpha \\nabla_w f $$$$ w = w - v_t    $$\n",
    "\n",
    "The momentum $m$ is commonly set to $0.9$.\n",
    "\n",
    "#### Adagrad\n",
    "\n",
    "SGD manipulates the learning rate globally and equally for all parameters. Tuning the learning rates is an expensive process, so much work has gone into devising methods that can adaptively tune the learning rates, and even do so per parameter.\n",
    "\n",
    "Adagrad is an algorithm for gradient-based optimization that does just this: It adapts the learning rate to the parameters, performing larger updates for infrequent and smaller updates for frequent parameters.\n",
    "\n",
    "$$ c = c + (\\nabla_w f)^2 $$$$ w = w - \\frac{\\alpha}{\\sqrt{c}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3cSy4_H6aEi"
   },
   "source": [
    "## 3. CNN (Convolutional neural network)\n",
    "\n",
    "The previously mentioned multilayer perceptrons represent the most general and powerful feedforward neural network model possible; they are organised in layers, such that every neuron within a layer receives its own copy of all the outputs of the previous layer as its input. This kind of model is perfect for the right kind of problem – learning from a fixed number of (more or less) unstructured parameters.\n",
    "\n",
    "> However, consider what happens to the number of parameters (weights) of such a model when being fed raw image data (f.e. a $200 \\times 200$ pixel image connected to 1024 neurons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1647941009442,
     "user": {
      "displayName": "Jordi Vitrià",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmEyLlUae4iKg7mL0rlGD0T7qj1Bpbxe-TmXfZBog=s64",
      "userId": "02382397723117011615"
     },
     "user_tz": -60
    },
    "id": "gxR3h2-d6nGn",
    "outputId": "d885def5-f38f-4b96-85d8-b2343f436f6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40960000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200 * 200 * 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlCN_f8E7OZ2"
   },
   "source": [
    "The situation quickly becomes unmanageable as image sizes grow larger, way before reaching the kind of images people usually want to work with in real applications.\n",
    "\n",
    "A common solution is to downsample the images to a size where MLPs can safely be applied. However, if we directly downsample the image, we potentially lose a wealth of information; it would be great if we would somehow be able to still do some useful (without causing an explosion in parameter count) processing of the image, prior to performing the downsampling.\n",
    "\n",
    "It turns out that there is a very efficient way of pulling this off, and it makes advantage of the structure of the information encoded within an image – it is assumed that pixels that are spatially closer together will \"cooperate\" on forming a particular feature of interest much more than ones on opposite corners of the image. Also, if a particular (smaller) feature is found to be of great importance when defining an image's label, it will be equally important if this feature was found anywhere within the image, regardless of location.\n",
    "\n",
    "Enter the convolution operator. Given a two-dimensional image, $I$, and a small matrix, $K$ of size $h \\times w$, (known as a convolution kernel), which we assume encodes a way of extracting an interesting image feature, we compute the convolved image, $I∗K$, by overlaying the kernel on top of the image in all possible ways, and recording the sum of elementwise products between the image and the kernel:\n",
    "\n",
    "$$\n",
    "output(x,y) = (I \\otimes K)(x,y) = \\sum_{m=0}^{M-1} \\sum_{n=1}^{N-1} K(m,n) I(x-n, y-m)\n",
    "$$\n",
    "\n",
    "The convolution operator forms the fundamental basis of the convolutional layer of a CNN. The layer is completely specified by a certain number of kernels, $K$, and it operates by computing the convolution of the output images of a previous layer with each of those kernels, afterwards adding the biases (one per each output image). Finally, an activation function, $\\sigma$, may be applied to all of the pixels of the output images. \n",
    "\n",
    "Typically, the input to a convolutional layer will have $d$ channels (e.g., red/green/blue in the input layer), in which case the kernels are extended to have this number of channels as well.\n",
    "\n",
    "Note that, since all we're doing here is addition and scaling of the input pixels, the kernels may be learned from a given training dataset via gradient descent, exactly as the weights of an MLP. In fact, an MLP is perfectly capable of replicating a convolutional layer, but it would require a lot more training time (and data) to learn to approximate that mode of operation.\n",
    "\n",
    "https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2\n",
    "\n",
    "## 4. Pooling\n",
    "\n",
    "In fact, after a convolutional layer there are two kinds of non linear functions that are usually applied: non-linear activation functions such as sigmoids or ReLU and **pooling**. Pooling layers are used with the purpose to progressively reduce the spatial size of the image to achieve scale invariance. The most common layer is the *maxpool* layer. Basically a maxpool of $2 \\times 2$ causes a filter of 2 by 2 to traverse over the entire input array and pick the largest element from the window to be included in the next representation map. Pooling can also be implemented by using other criteria, such as averaging instead of taking the max element. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84854,
     "status": "ok",
     "timestamp": 1647975599801,
     "user": {
      "displayName": "Jordi Vitrià",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmEyLlUae4iKg7mL0rlGD0T7qj1Bpbxe-TmXfZBog=s64",
      "userId": "02382397723117011615"
     },
     "user_tz": -60
    },
    "id": "KvbTpVNS7COv",
    "outputId": "739fdd8d-96b0-4f23-ca0a-d741e46b2245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,570</span> (400.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m102,570\u001b[0m (400.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">102,570</span> (400.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m102,570\u001b[0m (400.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 45ms/step - accuracy: 0.7175 - loss: 0.8434 - val_accuracy: 0.9810 - val_loss: 0.0649\n",
      "Epoch 2/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 46ms/step - accuracy: 0.9517 - loss: 0.1628 - val_accuracy: 0.9885 - val_loss: 0.0400\n",
      "Epoch 3/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 46ms/step - accuracy: 0.9702 - loss: 0.1033 - val_accuracy: 0.9907 - val_loss: 0.0356\n",
      "Epoch 4/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 49ms/step - accuracy: 0.9768 - loss: 0.0783 - val_accuracy: 0.9910 - val_loss: 0.0344\n",
      "Epoch 5/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 49ms/step - accuracy: 0.9793 - loss: 0.0722 - val_accuracy: 0.9898 - val_loss: 0.0356\n",
      "Epoch 6/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 49ms/step - accuracy: 0.9838 - loss: 0.0572 - val_accuracy: 0.9920 - val_loss: 0.0277\n",
      "Epoch 7/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - accuracy: 0.9850 - loss: 0.0519 - val_accuracy: 0.9917 - val_loss: 0.0287\n",
      "Epoch 8/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - accuracy: 0.9870 - loss: 0.0438 - val_accuracy: 0.9933 - val_loss: 0.0260\n",
      "Epoch 9/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 49ms/step - accuracy: 0.9877 - loss: 0.0423 - val_accuracy: 0.9943 - val_loss: 0.0239\n",
      "Epoch 10/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 46ms/step - accuracy: 0.9900 - loss: 0.0350 - val_accuracy: 0.9948 - val_loss: 0.0238\n",
      "Epoch 11/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 47ms/step - accuracy: 0.9893 - loss: 0.0366 - val_accuracy: 0.9948 - val_loss: 0.0197\n",
      "Epoch 12/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - accuracy: 0.9898 - loss: 0.0332 - val_accuracy: 0.9942 - val_loss: 0.0301\n",
      "Epoch 13/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 47ms/step - accuracy: 0.9918 - loss: 0.0284 - val_accuracy: 0.9935 - val_loss: 0.0264\n",
      "Epoch 14/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - accuracy: 0.9915 - loss: 0.0286 - val_accuracy: 0.9948 - val_loss: 0.0240\n",
      "Epoch 15/15\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 46ms/step - accuracy: 0.9924 - loss: 0.0242 - val_accuracy: 0.9950 - val_loss: 0.0250\n",
      "Test loss: 0.02244691550731659\n",
      "Test accuracy: 0.9940000176429749\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\"\"\"\n",
    "## Prepare the data\n",
    "\"\"\"\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\"\"\"\n",
    "## Build the model\n",
    "\"\"\"\n",
    "\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\"\"\"\n",
    "## Train the model\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "\"\"\"\n",
    "## Evaluate the trained model\n",
    "\"\"\"\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8-AH0Zy96Aa"
   },
   "source": [
    "## 5. Recurrent Neural Networks\n",
    "\n",
    "\n",
    "Classical neural networks, including convolutional ones, suffer from two severe limitations:\n",
    "\n",
    "+ They only accept a fixed-sized vector as input and produce a fixed-sized vector as output.\n",
    "+ They do not consider the sequential nature of some data (language, video frames, time series, etc.) \n",
    "\n",
    "Recurrent neural networks (RNN) overcome these limitations by allowing to operate over sequences of vectors (in the input, in the output, or both). RNNs are called recurrent because they perform the same task for every element of the sequence, with the output depending on the previous computations. The basic formulas of a simple RNN are:\n",
    "\n",
    "$$ s_t = f_1 (Ux_t + W s_{t-1}) $$\n",
    "$$ y_t = f_2 (V s_t) $$\n",
    "\n",
    "These equations basically say that the current network state, commonly known as hidden state, $s_t$ is a function $f_1$ of the previous hidden state $s_{t-1}$ and the current input $x_t$. $U, V, W$ matrices are the parameters of the function. \n",
    "\n",
    "Given an input sequence, we apply RNN formulas in a recurrent way until we process all input elements. The RNN shares the parameters  $U,V,W$ across all recurrent steps. We can think of the hidden state  as a memory of the network that captures information about the previous steps.\n",
    "\n",
    "The novelty of this type of network is that we we have encoded in the very architecture of the network a sequence modeling scheme that has been in used in the past to predict time series as well as to model language. In contrast to the precedent architectures we have introduced, now the hidden layers are indexed by both 'spatial' and 'temporal' index. \n",
    "\n",
    "The inputs of a recurrent network are always vectors, but we can process sequences of symbols/words by representing these symbols by numerical vectors.\n",
    "\n",
    "Let's suppose we want to classify a phrase or a series of words. Let $x^1, ...,x^{C}$ the word vectors corresponding to a corpus with $C$ symbols. Then, the relationship to compute the hidden layer output features at each time-step $t$ is $h_t = \\sigma(W s_{t-1} + U x_{t})$, where:\n",
    "\n",
    "+ $x_{t} \\in \\mathbf{R}^{d}$ is input word vector at time $t$. \n",
    "+ $U \\in \\mathbf{R}^{D_h \\times d}$ is the weights matrix of the input word vector, $x_t$.\n",
    "+ $W \\in \\mathbf{R}^{D_h \\times D_h}$ is the weights matrix of the output of the previous time-step, $t-1$.\n",
    "+ $s_{t-1}  \\in \\mathbf{R}^{D_h}$ is the output of the non-linear function at the previous time-step, $t-1$. \n",
    "+ $\\sigma ()$ is the non-linearity function (normally, ``tanh``).\n",
    "\n",
    "\n",
    "The output of this network is $\\hat{y}_t = softmax (V h_t)$, that represents the output probability distribution over the vocabulary at each time-step $t$.  \n",
    "\n",
    "Essentially, $\\hat{y}_t$ is the next predicted word given the document context score so far (i.e. $h_{t-1}$) and the last observed word vector $x^{(t)}$. \n",
    "\n",
    "The loss function used in RNNs is often the cross entropy error:\n",
    "\n",
    "$\n",
    "\tL^{(t)}(W) = - \\sum_{j=1}^{|V|} y_{t,j} \\times log (\\hat{y}_{t,j})\n",
    "$\n",
    "\n",
    "The cross entropy error over a corpus of size $C$ is:\n",
    "\n",
    "$\n",
    "\tL = \\frac{1}{C} \\sum_{c=1}^{C} L^{(c)}(W) = - \\frac{1}{C} \\sum_{c=1}^{C} \\sum_{j=1}^{|V|} y_{c,j} \\times log (\\hat{y}_{c,j})\n",
    "$\n",
    "\n",
    "These simple RNN architectures have been shown to be too prone to forget information when sequences are long and they are also very unstable when trained. For this reason several alternative architectures have been proposed. These alternatives are based on the presence of *gated units*. Gates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation. The two most important alternative RNN are Long Short Term Memories (LSTM) and Gated Recurrent Units (GRU) networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 202071,
     "status": "error",
     "timestamp": 1647941500999,
     "user": {
      "displayName": "Jordi Vitrià",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgmEyLlUae4iKg7mL0rlGD0T7qj1Bpbxe-TmXfZBog=s64",
      "userId": "02382397723117011615"
     },
     "user_tz": -60
    },
    "id": "Ayj2JDJ87zKu",
    "outputId": "83c01988-b334-432a-a180-2a161e08f018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n",
      "total chars: 57\n",
      "nb sequences: 200285\n",
      "Vectorization...\n",
      "Build model...\n",
      "Epoch 1/60\n",
      "\u001b[1m 207/1565\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:27\u001b[0m 65ms/step - loss: 2.9331"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 105\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m    103\u001b[0m print_callback \u001b[38;5;241m=\u001b[39m LambdaCallback(on_epoch_end\u001b[38;5;241m=\u001b[39mon_epoch_end)\n\u001b[0;32m--> 105\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mprint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/keras/src/backend/tensorflow/trainer.py:318\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    317\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 318\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    320\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''Example script to generate text from Nietzsche's writings.\n",
    "At least 20 epochs are required before the generated text\n",
    "starts sounding coherent.\n",
    "It is recommended to run this script on GPU, as recurrent\n",
    "networks are quite computationally intensive.\n",
    "If you try this script on new data, make sure your corpus\n",
    "has at least ~100k characters. ~1M is better.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "\n",
    "path = get_file('nietzsche.txt', origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "with io.open(path, encoding='utf-8') as f:\n",
    "    text = f.read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "\n",
    "\n",
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = RMSprop(learning_rate=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()\n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=60,\n",
    "          callbacks=[print_callback])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NeuralNetworks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
